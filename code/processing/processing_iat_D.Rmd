---
title: "Data processing"
author: "Jamie Cummins & Ian Hussey"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

```{r}

library(tidyverse)
library(parallel)
library(boot)

```

## Load data with tidying and exclusions already done (in the main processing script)

```{r}

all_exclusions_applied_df <- read_rds("../../data/processed/data_trials_for_bootstrapping.rds") |>
  filter(measure %in% c("iat", "biat", "siat"))

```

# bootstrap 95% CIs and compare against neutral point 

```{r}

n_boots = 2000
subset_sample = TRUE # to reduce processing time for testing

if(TRUE){
  
  D_score <- function(data, i) {
    data_with_indexes <- data[i,] # boot function requires data and index
    b  <- na.omit(data_with_indexes$score[data_with_indexes$trial_consistency == "inconsistent"])
    a  <- na.omit(data_with_indexes$score[data_with_indexes$trial_consistency == "consistent"])
    mean_b <- mean(b)
    mean_a <- mean(a)
    sd <- sd(c(a, b))
    D <- (mean_b-mean_a)/sd
    return(D)
  }
  
  bootstrap_D_score <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = D_score, 
                 R         = n_boots, 
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores()-1)
    
    # results <- boot::boot.ci(fit, conf = 0.95, type = c("bca"))
    # 
    # output <- 
    #   tibble(method   = "bca",
    #          estimate = fit$t0,
    #          ci_lower = results$bca[4],
    #          ci_upper = results$bca[5])
    # returns error: estimated adjustment 'w' is infinite
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("basic"))
    
    output <- 
      tibble(method   = "basic",
             estimate = fit$t0,
             ci_lower = results$basic[4],
             ci_upper = results$basic[5])
    
    return(output)
  }
  
  
  if(subset_sample == TRUE) {
    trials_to_process <- all_exclusions_applied_df |>
      slice_head(n = 500000)
    } else {
    trials_to_process <- all_exclusions_applied_df
  }
  
  # bootstrap D scores 
  D_scores <- trials_to_process |>
    mutate(session_id = as.factor(SESSION_ID),
           trial_consistency = as.character(trial_consistency)) |>
    
    # ensure a sufficient number of observations per person per measure per trial type
    group_by(session_id, measure, domain, trial_consistency) |>
    filter(n() >= 10) |>
    
    # remove those who do not have sufficient observations for both trials per measure
    group_by(session_id, domain, measure) |>
    filter(n_distinct(trial_consistency) == 2) |>
    
    # do bootstrapping scores
    group_by(session_id, measure, domain) |>
    do(bootstrap_D_score(data = .)) |>
    ungroup() |>
    mutate(sig = ifelse((ci_lower < 0 & ci_upper < 0) | (ci_lower > 0 & ci_upper > 0), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) 
  
}

data_processed <- data_processed |>
  mutate(sig = ifelse((ci_lower < 0 & ci_upper < 0) | (ci_lower > 0 & ci_upper > 0), TRUE, FALSE),
         ci_width = ci_upper - ci_lower) 

```

# write to disk

```{r}

data_processed <- D_scores |>
  drop_na()
  
write_rds(data_processed, "../../data/processed/data_processed_iat_D.rds")

```



