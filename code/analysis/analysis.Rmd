---
title: "Comparing 6 implicit measures' suitability for individual use"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- add demographics? or rely on Bar-Anan and Nosek's descriptions?

```{r, include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE,
                      cache.lazy=FALSE)
```

```{r}

# dependencies
library(tidyverse)
library(knitr)
library(kableExtra)
library(boot)
library(parallel)
library(bayestestR)
library(patchwork)
library(mdthemes)
library(lme4)
library(sjPlot)
library(emmeans)
library(ggstance)
library(janitor)
# library(merTools) called via merTools:: to avoid namespace collisions between MASS and dplyr


# set seed for reproducibility
set.seed(42)

# options
options(knitr.table.format = "html") # necessary configuration of tables

# disable scientific notation
options(scipen = 999) 


# function to round all numeric vars in a data frame
round_df <- function(df, n_digits = 3) {
  require(janitor)
  df %>% mutate_if(is.numeric, janitor::round_half_up, digits = n_digits)
}

```

# Sample descriptives

```{r}

# data_outliers %>%
#   distinct(session_id, .keep_all = TRUE) %>%
#   count(rt_outlier) %>%
#   kable() %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
# 
# data_descriptives <- data_outliers_removed %>%
#   distinct(session_id, .keep_all = TRUE)
# 
# data_descriptives %>%
#   count(domain) %>%
#   kable() %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
# 
# data_descriptives %>%
#   count(domain) %>%
#   summarize(total_n = sum(n),
#             min_n_per_domain = min(n),
#             max_n_per_domain = max(n),
#             mean_n_per_domain = round(mean(n, na.rm = TRUE), 2),
#             sd_n_per_domain = round(sd(n, na.rm = TRUE), 2)) %>%
#   gather() %>%
#   kable() %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
# 
# data_descriptives %>%
#   summarize(min_age  = round(min(age, na.rm = TRUE), 2),
#             max_age  = round(max(age, na.rm = TRUE), 2),
#             mean_age = round(mean(age, na.rm = TRUE), 2),
#             sd_age   = round(sd(age, na.rm = TRUE), 2)) %>%
#   gather() %>%
#   kable() %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
# 
# data_descriptives %>%
#   count(gender) %>%
#   kable() %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Load scored data

```{r}

# for development
data_processed_testing <- read_rds("../../data/processed/data_processed_testing.rds") |>
  mutate(domain = as.factor(str_to_sentence(domain)),
         measure = case_when(measure == "iat"   ~ "IAT",
                             measure == "biat"  ~ "Brief IAT",
                             measure == "siat" ~ "SC-IAT",
                             measure == "amp"   ~ "AMP",
                             measure == "gnat"  ~ "GNAT",
                             measure == "ept"   ~ "EPT"),
         measure = fct_relevel(measure, "IAT", "Brief IAT", "SC-IAT", "AMP", "GNAT", "EPT"))

data_processed <- data_processed_testing

# # for realz
# data_processed_full <- read_rds("../../data/processed/data_processed.rds") |>
#   mutate(domain = as.factor(str_to_sentence(domain)),
#          measure = case_when(measure == "iat"   ~ "IAT",
#                              measure == "biat"  ~ "Brief IAT",
#                              measure == "siat"  ~ "SC-IAT",
#                              measure == "amp"   ~ "AMP",
#                              measure == "gnat"  ~ "GNAT",
#                              measure == "ept"   ~ "EPT"),
#          measure = fct_relevel(measure, "IAT", "Brief IAT", "SC-IAT", "AMP", "GNAT", "EPT")) |>
#   drop_na()
# 
# data_processed <- data_processed_full |>
#   anti_join(data_processed_testing, by = c("session_id", "measure", "domain"))
# 
# percent_split <- round_half_up(nrow(data_processed_testing)/nrow(data_processed_full)*100, 0)

```

The "training" dataset which we used to refine the code with was `r percent_split`% of the full dataset.

# Caterpillar plot

```{r fig.height=7, fig.width=6}

p_cis_by_domain <- 
  data_processed %>%
  arrange(estimate) %>%
  group_by(domain, measure) %>%
  mutate(ordered_id = row_number()/n()) %>%
  ungroup() %>%
  ggplot() +
  geom_linerange(aes(x = ordered_id, ymin = ci_lower, ymax = ci_upper, color = sig),
                 alpha = 1) +
  geom_point(aes(ordered_id, estimate), size = 0.5, shape = "square") +
  geom_hline(yintercept = 0.50, linetype = "dotted") +
  mdthemes::md_theme_linedraw() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = "top") +
  scale_color_viridis_d(end = 0.6, direction = -1) +
  xlab("Ranked participant") +
  ylab("A score") +
  labs(color = "95% CI excludes zero point") + 
  facet_grid(measure ~ domain)

p_cis_by_domain

```

# CI widths

Not meta analyzed as extreme skew in data means that residuals are very non-normal, violating assumptions and underestimating MAP estimates. Instead I simply present MAP estimates. 

## MAP CI width

```{r}

data_map_ci_widths <- data_processed %>%
  group_by(domain, measure) %>%
  do(point_estimate(.$ci_width, centrality = "MAP")) %>%
  ungroup()

data_map_ci_widths %>%
  pivot_wider(names_from = measure, values_from = MAP) %>%
  round_df(2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Plot by domain and measure

```{r}

data_ci_width_map <- data_processed %>%
  group_by(domain, measure) %>%
  do(point_estimate(.$ci_width, centrality = "MAP")) %>%
  ungroup() %>%
  mutate(domain = fct_rev(domain)) 

# plot
p_ci_widths <- 
  ggplot(data_ci_width_map, aes(MAP, fct_rev(measure), color = domain, shape = domain)) + 
  geom_point(position = position_dodge(width = 0.75)) +
  scale_shape_manual(values = c(17, 16, 15, 19)) +
  scale_color_viridis_d(begin = 0.2, end = 0.8, direction = -1) +
  mdthemes::md_theme_linedraw() +
  labs(x = "Highest probability (MAP) 95% CI width",
       y = "",
       color = "Domain",
       shape = "Domain") + 
  theme(legend.position = "top")
  
p_ci_widths

```

# Proportion different from zero

## Calculate scores

```{r}

data_diff_zero <- 
  data_processed %>%
  mutate(domain = as.factor(domain)) %>%
  group_by(domain, measure) %>%
  summarize(proportion_diff_zero = mean(sig, na.rm = TRUE),
            variance = plotrix::std.error(sig, na.rm = TRUE)^2,
            .groups = "drop") %>%
  # logit transform for analysis
  mutate(proportion_diff_zero_logit = boot::logit(proportion_diff_zero)) %>%
  filter(!(proportion_diff_zero == 0 & variance == 0)) %>%
  mutate(variance = ifelse(variance == 0, 0.0001, variance)) 

```

## Plot scores

```{r}

p_diff_zero <- 
  data_diff_zero %>%
  mutate(domain = fct_reorder(domain, proportion_diff_zero, .fun = mean)) %>%
  ggplot(aes(proportion_diff_zero, fct_rev(measure), color = domain, shape = domain)) +
  geom_linerangeh(aes(xmin = proportion_diff_zero - sqrt(variance)*1.96,
                      xmax = proportion_diff_zero + sqrt(variance)*1.96),
                  position = position_dodge(width = 0.5)) + 
  geom_point(position = position_dodge(width = 0.5)) +
  scale_shape_manual(values = c(17, 16, 15, 19)) +
  scale_color_viridis_d(begin = 0.2, end = 0.8, direction = -1) +
  mdthemes::md_theme_linedraw() +
  labs(x = "Proportion of scores different from zero point",
       y = "",
       color = "Domain",
       shape = "Domain") + 
  theme(legend.position = "top") +
  xlim(0, 1)

p_diff_zero

```

## Meta

```{r}

# fit model
fit_diff_zero <-
  lmer(proportion_diff_zero_logit ~ 1 + measure + (1 | domain),
       weights = 1/variance, 
       data = data_diff_zero)

# extract re Tau
results_re_tau_diff_zero <- fit_diff_zero %>%
  merTools::REsdExtract() %>%
  as_tibble(rownames = "domain") %>%
  rename(tau = value) 

# extract marginal means
results_diff_zero <- 
  summary(emmeans(fit_diff_zero, ~ measure)) %>%
  dplyr::select(measure, estimate = emmean, se = SE, ci_lower = lower.CL, ci_upper = upper.CL) %>%
  mutate(pi_lower = estimate - (1.96 * sqrt(se^2 + results_re_tau_diff_zero$tau^2)), 
         pi_upper = estimate + (1.96 * sqrt(se^2 + results_re_tau_diff_zero$tau^2))) |>
  select(-se) |>
  mutate_if(is.numeric, boot::inv.logit)

# plot
p_prop_nonzero <- 
  ggplot(results_diff_zero, aes(fct_rev(measure), estimate)) +
  #geom_linerange(aes(ymin = pi_lower, ymax = pi_upper), size = 0.5, linetype = "solid") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point(size = 2.5) +
  mdthemes::md_theme_linedraw() +
  scale_y_continuous(breaks = c(0, .25, .5, .75, 1), labels = c("0.00<br/>(Worse)", "0.25", "0.50", "0.75", "1.00<br/>(Better)")) +
  labs(x = "",
       y = "Proportion of participants with non-zero scores<br/>") + 
  theme(legend.position = "none") +
  coord_flip(ylim = c(0, 1))

p_prop_nonzero

results_diff_zero %>%
  round_df(2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# tests
data_emms_diff_zero <- emmeans(fit_diff_zero, list(pairwise ~ measure), adjust = "holm") 

summary(data_emms_diff_zero)$`pairwise differences of measure` %>%
  as.data.frame() %>%
  select(comparison = 1, p.value) %>%
  mutate(p.value = ifelse(p.value < .001, "< .001", round_half_up(p.value, 3))) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Proportion different from one another

Note: Discriminability between a score and zero can be determined using the CI, because zero is a known value and only the score is measured with uncertainty. However, discriminability between two scores must take into account the uncertainty in the estimation of both scores. Weir (2005) argues that such an interval can be estimated by expanding the CIs by sqrt(2). Here I refer to these intervals as Discriminability Intervals (DIs).

## Calculate scores

Many have argued that the zero point is arbitrary and not a useful reference point. Instead of asking "what proportion of A scores are different from the neutral point (0.50)?", we could also ask "what proportion of A scores are different from one another?"

```{r}

# helper function to apply workflow to each resample
discriminability <- function(data, i) {
  
  data_with_indexes <- data[i,] # boot function requires data and index
  
  estimate <- data_with_indexes$estimate
  di_lower <- data_with_indexes$di_lower 
  di_upper <- data_with_indexes$di_upper

  n_estimate <- length(estimate)
  n_di_lower <- length(di_lower)
  n_di_upper <- length(di_upper)
  
  r_estimate <- sum(rank(c(estimate, di_lower))[1:n_estimate])
  r_di_upper <- sum(rank(c(di_upper, estimate))[1:n_di_upper])
  
  prob_estimate_inferior_to_di_lower <- 1 - (r_estimate / n_estimate - (n_estimate + 1) / 2) / n_di_lower
  prob_estimate_superior_to_di_upper <- 1 - (r_di_upper / n_di_upper - (n_di_upper + 1) / 2) / n_estimate
  
  probability_estimates_outside_cis <- (prob_estimate_inferior_to_di_lower + prob_estimate_superior_to_di_upper)
  
  return(probability_estimates_outside_cis)
  
}

bootstrap_discriminability <- function(data){
  
  require(dplyr)
  require(boot)
  
  fit <- 
    boot::boot(data      = data, 
               statistic = discriminability, 
               R         = 3000,
               sim       = "ordinary", 
               stype     = "i",
               parallel  = "multicore", 
               ncpus     = parallel::detectCores())
  
  results <- boot::boot.ci(fit, conf = 0.95, type = c("bca"))
  
  output <- 
    tibble(
      method   = "bca",
      estimate = fit$t0,
      ci_lower = results$bca[4],
      ci_upper = results$bca[5]
    )
  
  return(output)
}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("../../data/results/data_discriminability.csv")) {
  
  data_discriminability <- read_csv("../../data/results/data_discriminability.csv") |>
    mutate(measure = fct_relevel(measure, "IAT", "Brief IAT", "SC-IAT", "AMP", "GNAT", "EPT"))
  
} else {
  
  # bootstrap D scores 
  data_discriminability <- data_processed |>
    # expand CIs by sqrt(2) to form discriminability intervals
    mutate(di_lower = estimate - (estimate - ci_lower)*sqrt(2),
           di_upper = estimate + (ci_upper - estimate)*sqrt(2),
           di_width = di_upper - di_lower) |>
    select(session_id, domain, measure, estimate, di_upper, di_lower) |>
    group_by(domain, measure) |>
    do(bootstrap_discriminability(data = .)) |>
    ungroup() |>
    rename(proportion_discriminable = estimate) |>
    # logit transform for analysis
    mutate(variance = ((ci_upper - ci_lower)/(1.96*2))^2,
           domain = as.factor(domain),
           measure = fct_relevel(measure, "IAT", "Brief IAT", "SC-IAT", "AMP", "GNAT", "EPT")) %>%
    filter(!(proportion_discriminable == 0 & variance == 0)) %>%
    mutate(variance = ifelse(variance == 0, 0.0001, variance)) |>
    # model cannot be run on zero variance or 0 or 1 logit, so offset by a minuscule amount
    mutate(
      proportion_discriminable_temp = case_when(proportion_discriminable < 0.001 ~ 0.001, 
                                                proportion_discriminable > 0.999 ~ 0.999,
                                                TRUE ~ proportion_discriminable),
      proportion_discriminable_logit = boot::logit(proportion_discriminable_temp)
    ) %>%
    select(-proportion_discriminable_temp)
  
  # save to disk
  write_csv(data_discriminability, "../../data/results/data_discriminability.csv")

}

```

## Meta

```{r}

# fit meta analytic model
fit_disciminability <- 
  lmer(proportion_discriminable_logit ~ 1 + measure + (1 | domain), 
       weights = 1/variance, 
       data = data_discriminability)

# extract re Tau
results_re_tau_disciminability <- fit_disciminability %>%
  merTools::REsdExtract() %>%
  as_tibble(rownames = "measure") %>%
  rename(tau = value) 

# extract marginal means
results_disciminability <-
  summary(emmeans(fit_disciminability, ~ measure)) %>%
  dplyr::select(measure, estimate = emmean, se = SE, ci_lower = lower.CL, ci_upper = upper.CL) %>%
  mutate(pi_lower = estimate - (1.96 * sqrt(se^2 + results_re_tau_disciminability$tau^2)),  # as in metafor package's implementation of credibility intervals, see metafor::predict.rma.R
         pi_upper = estimate + (1.96 * sqrt(se^2 + results_re_tau_disciminability$tau^2))) |>
  select(-se) |>
  mutate_if(is.numeric, boot::inv.logit)
  
# plot
p_prop_discriminable <-
  ggplot(results_disciminability, aes(fct_rev(measure), estimate)) +
  #geom_linerange(aes(ymin = pi_lower, ymax = pi_upper), size = 0.5, linetype = "solid") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point(size = 2.5) +
  scale_y_continuous(breaks = c(0, .25, .5, .75, 1), labels = c("0.00<br/>(Worse)", "0.25", "0.50", "0.75", "1.00<br/>(Better)")) +
  scale_shape_manual(values = c(15, 16)) +
  scale_color_viridis_d(begin = 0.3, end = 0.7) +
  mdthemes::md_theme_linedraw() +
  labs(x = "",
       y = "Proportion of participants<br/>whose scores differ from one another<br/>") +
  theme(legend.position = "none") +
  coord_flip(ylim = c(0, 1))

p_prop_discriminable 

results_disciminability %>%
  round_df(2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# tests
data_emms_disciminability <- emmeans(fit_disciminability, list(pairwise ~ measure), adjust = "holm") 

summary(data_emms_disciminability)$`pairwise differences of measure` %>%
  as.data.frame() %>%
  select(comparison = 1, p.value) %>%
  mutate(p.value = ifelse(p.value < .001, "< .001", round_half_up(p.value, 3))) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# CI widths as a proportion of observed range

NB observed range of confidence intervals

## Calculate scores

```{r}

## calculate observed ranges 
observed_range_estimates <- data_processed %>%
  group_by(measure, domain) %>%
  dplyr::summarize(min = min(ci_lower, na.rm = TRUE),
                   max = max(ci_upper, na.rm = TRUE),
                   .groups = "drop") %>%
  mutate(range = max - min) 

# calculate CI / range 
data_ci_width_proportions <- data_processed %>%
  # join this data into the original data
  full_join(observed_range_estimates, by = c("measure", "domain")) %>%
  # calculate ci width as a proportion of observed range
  mutate(ci_width_proportion = ci_width / range,
         domain = as.factor(domain),
         measure = fct_relevel(measure, "IAT", "Brief IAT", "SC-IAT", "AMP", "GNAT", "EPT")) %>%
  # logit transform
  mutate(ci_width_proportion_temp = case_when(ci_width_proportion < 0.0001 ~ 0.0001,
                                              ci_width_proportion > 0.9999 ~ 0.9999,
                                              TRUE ~ ci_width_proportion),
         ci_width_proportion_logit = boot::logit(ci_width_proportion_temp)) %>%
  select(-ci_width_proportion_temp) 

```

## Analysis

```{r}

# fit model
fit_ci_width_proportions <- 
  lmer(ci_width_proportion_logit ~ 1 + measure + (1 | domain), 
       data = data_ci_width_proportions)

# extract re Tau
results_re_tau_ci_width_proportions <- fit_ci_width_proportions %>%
  merTools::REsdExtract() %>%
  as_tibble(rownames = "measure") %>%
  rename(tau = value) 

# extract marginal means
results_ci_width_proportions <- 
  summary(emmeans(fit_ci_width_proportions, ~ measure)) %>%
  dplyr::select(measure, estimate = emmean, se = SE, ci_lower = asymp.LCL, ci_upper = asymp.UCL) %>%
  mutate(pi_lower = estimate - (1.96 * sqrt(se^2 + results_re_tau_ci_width_proportions$tau^2)),
         pi_upper = estimate + (1.96 * sqrt(se^2 + results_re_tau_ci_width_proportions$tau^2))) %>%
  select(-se) %>%
  mutate_if(is.numeric, boot::inv.logit)

# plot
p_ci_width_proportion_observed_range <- 
  ggplot(results_ci_width_proportions, aes(fct_rev(measure), estimate)) +
  #geom_linerange(aes(ymin = pi_lower, ymax = pi_upper), size = 0.5, linetype = "solid") +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) +
  geom_point(size = 2.5) +
  mdthemes::md_theme_linedraw() +
  scale_y_continuous(breaks = c(0, .25, .5, .75, 1), labels = c("0.00<br/>(Better)", "0.25", "0.50", "0.75", "1.00<br/>(Worse)")) +
  labs(x = "",
       y = "Proportion of observed range covered <br/>by individual participants' 95% CIs") +
  theme(legend.position = "none") +
  coord_flip(ylim = c(0, 1))

p_ci_width_proportion_observed_range

results_ci_width_proportions %>%
  round_df(2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# tests
data_emms_ci_width_proportions <- emmeans(fit_ci_width_proportions, list(pairwise ~ measure), adjust = "holm") 

summary(data_emms_ci_width_proportions)$`pairwise differences of measure` %>%
  as.data.frame() %>%
  select(comparison = 1, p.value) %>%
  mutate(p.value = ifelse(p.value < .001, "< .001", round_half_up(p.value, 3))) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Combined plots

## Plot 1

Plot 1 is merely illustrative. It shows the bootstrapped CIs for all participants, split by domain and measure.

```{r fig.height=7, fig.width=6}

p_cis_by_domain

dir.create("plots")

ggsave(filename  = "plots/figure_1_cis_by_domain.pdf",
       plot      = p_cis_by_domain,
       device    = "pdf",
       # path      = NULL,
       # dpi       = 300,
       units     = "in",
       width     = 6,
       height    = 7,
       limitsize = TRUE)

```

## Plot 2

Most probable CI width for A scores. 

NB I elected not to meta-analyze these widths as they demonstrate very large skew at the individual level, which violate the assumptions of linear meta-analysis and underestimate the typical width (ie estimated mean widths << MAP observed widths). Rather than meta analyze, I simply report the domain and measure level MAP values. More informative and valid analyses are presented below. 

```{r}

p_ci_widths

ggsave(filename  = "plots/figure_2_ci_widths.pdf",
       plot      = p_ci_widths,
       device    = "pdf",
       # path      = NULL,
       # dpi       = 300,
       units     = "in",
       width     = 4,
       height    = 3,
       limitsize = TRUE)

```

## Plot 3

The results of three hierarchical/meta analytic models are presented below, all of which provide information via different methods regarding how informative an individual participants' A scores are in terms of being able to state that they demonstrated evidence of a bias/effect/implicit attitude, whether that individual can be discriminated from other individuals in the same domain and on the same measure, and how much of the range of observed scores an individuals score's CI spans.  

(1) a meta-analysis of the proportion of participants that show non-zero scores (i.e., whose A scores' 95% CIs exclude zero), (2) the proportion of scores that are discriminable from one another. Pairwise comparisons are made between all participants' scores within a domain and measure, and the proportion that lie outside one-another's CIs can be inferred to be different from one another (i.e., are discriminable as different from one another). This analysis is useful because it avoids the issue or debate around how meaningful a score's zero point is (i.e., A = 0.50) or whether it is a meaningful reference point. That is, previous research has argued that A = 0.50 cannot be inferred to represent no bias. Discriminability is agnostic to any individual comparison point and avoids this issue. (3) A meta analysis of the ratio between each participants' score and the maximum observed range of scores for that domain and measure. I.e., given the observed range of scores across participants, what proportion of that range did each individual participant's score's Confidence Interval span. If each individual's CIs are compatible with a large proportion of the total range of all observed scores, then each score is so poorly estimated as to tell us very little about where on the spectrum each participant lies. 

Note that the theoretical max possible range of A scores is 0 to 1, but such extreme scores are practically impossible on some tasks. As such, in order to understand the CI width in terms of realistic data I standardize CI widths by the observed range of scores for each domain and measure. 

```{r fig.height=7, fig.width=6}

p_combined <- 
  p_prop_nonzero +
  p_prop_discriminable + 
  p_ci_width_proportion_observed_range +
  plot_layout(ncol = 1)

p_combined

ggsave(filename  = "plots/figure_3_metaanalyses.pdf",
       plot      = p_combined,
       device    = "pdf",
       # path      = NULL,
       # dpi       = 300,
       units     = "in",
       width     = 5,
       height    = 7,
       limitsize = TRUE)

```

# Session info

```{r}

sessionInfo()

```
