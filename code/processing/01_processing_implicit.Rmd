---
title: "Data processing"
author: "Jamie Cummins & Ian Hussey"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

```{r}

library(tidyverse)
library(parallel)
library(boot)

# raw_trial_level_df <- read.delim("../../data/raw/impraw.txt") 
# raw_sessions_df <- read.delim("../../data/raw/allds.txt")
# 
# write_rds(raw_trial_level_df, "../../data/raw/impraw.rds", compress = "gz")
# write_rds(raw_sessions_df, "../../data/raw/allds.rds", compress = "gz")

raw_trial_level_df <- read_rds("../../data/raw/impraw.rds")
raw_sessions_df <- read_rds("../../data/raw/allds.rds")

```

# screen and identify the completed sessions and their corresponding measures

```{r}

completed_sessions_df <- raw_sessions_df |>
  select(User_ID, SESSION_ID, 
         contains(c("Race", "Pltc", "Self")), 
         -contains(c("21", "22", "31", "32", "33", 
                     "RT", "cgat"))) |>
  mutate(across(everything(),
                as.character)) |>
  pivot_longer(cols = -contains(c("ID")),
               names_to = "scale",
               values_to = "score") %>%
  filter(!is.na(score),
         scale != "race") |>
  separate(scale, 
           c("measure", "domain"),
           "(?!^)(?=[[:upper:]])")

```

# tidy the trial-level data and include only those completed cases

```{r}

trial_level_tasks_labelled_df <-
  raw_trial_level_df |>
  mutate(across(everything(),
                as.character)) |>
  
  # remove sessions with no complete implicit measures
  semi_join(completed_sessions_df, by = "SESSION_ID") |>
  mutate(measure_firstblock = case_when(TASK_NAME_S %in% c("BBlkBad", "BWhtGood",
                                                           "BRepBad", "BDemGood",
                                                           "BOtrBad", "BSlfGood") ~ "biat_con",
                                        TASK_NAME_S %in% c("BBlkGood", "BWhtBad",
                                                           "BRepGood", "BDemBad",
                                                           "BOtrGood", "BSlfBad") ~ "biat_incon",
                                        TASK_NAME_S %in% c("GBlkBad", "GWhtGood",
                                                           "GRepBad", "GDemGood",
                                                           "GOtrBad", "GSlfGood") ~ "gnat_con",
                                        TASK_NAME_S %in% c("GBlkGood", "GWhtBad",
                                                           "GRepGood", "GDemBad",
                                                           "GOtrGood", "GSlfBad") ~ "gnat_incon",
                                        TASK_NAME_S %in% c("eppltc", 
                                                           "eprace", "epself") ~ "ept",
                                        TASK_NAME_S %in% c("amppltc", 
                                                           "amprace", "ampself") ~ "amp",
                                        TASK_NAME_S %in% c("iwhtgood", 
                                                           "iDemGood", "iSlfGood") ~ "iat_con",
                                        TASK_NAME_S %in% c("iwhtbad", 
                                                           "iRepGood", "iSlfBad") ~ "iat_incon",
                                        TASK_NAME_S %in% c("scbdblk", "scbdotr",
                                                           "scbdrep", "scgddem",
                                                           "scgdslf", "scgdwht") ~ "siat_con",
                                        TASK_NAME_S %in% c("scgdblk", "scgdotr",
                                                           "scgdrep", "scbddem",
                                                           "scbdslf", "scbdwht") ~ "siat_incon",
                                        TASK_NAME_S %in% c("spdpltc", "spdrace",
                                                           "spdself") ~ "speededresponse",
                                        TRUE ~ "irrelevant"),
         domain = case_when(str_detect(TASK_NAME_S, "Blk|Wht|blk|wht|race") ~ "race",
                            str_detect(TASK_NAME_S, "Slf|Otr|slf|otr|self") ~ "self",
                            str_detect(TASK_NAME_S, "Dem|Rep|dem|rep|pltc") ~ "politics",
                            TRUE ~ "irrelevant")) |>
  filter(domain != "irrelevant",
         measure_firstblock != "irrelevant") |>
  separate(measure_firstblock,
           into = c("measure", "first_block"),
           sep = "_")

```

# define the metric to be scored

ie rt or accuracy

```{r}

block_consistent_terms <- "White People/Good|Self/Good|Democrats/Good|Good Words/White|Bad Words/Black|Good Words/Democrats|Bad Words/Republicans|Good Words/Self|Bad Words/Others"
block_inconsistent_terms <- "Black People/Good|Others/Good|Republicans/Good|Good Words/Black|Bad Words/White|Good Words/Republicans|Bad Words/Democrats|Good Words/Others|Bad Words/Self"
trial_consistent_terms <- "mtmmgore|mtmmkry|mtmmclnt|mtmmobm|mtmmbclnt|mtmmhclnt|Mine|Me|Myself|Self|\\[I\\]|epwm|epwf|mtmmwf|mtmmwm"
trial_inconsistent_terms <- "mtmmrgn|mtmmbsh|mtmmgln|mtmmcnd|They|Them|Their|Others|epbm|epbf|mtmmbf|mtmmbm"


critical_trials_df <- trial_level_tasks_labelled_df |>
  
  # keep only relevant blocks/trials
  filter(
    (measure == "iat" & BLOCK_NUMBER %in% c("2", "3", "5", "6"))
    |
    (measure == "biat" & BLOCK_NUMBER %in% c(1:8) & TRIAL_NUMBER %in% c(4:19))
    |
    (measure == "amp" & BLOCK_NUMBER %in% c(1:2) & str_detect(TRIAL_NAME_S, "[XXXXXX]|Grey", negate = TRUE))
    |
    (measure == "gnat" & BLOCK_NUMBER %in% c(1:8))
    |
    (measure == "ept" & BLOCK_NUMBER %in% c(1:3))
    |
    (measure == "siat")) |>
  mutate(trial_consistency = case_when(
    measure %in% c("iat", "biat", "gnat") & 
      str_detect(BLOCK_PAIRING_DEFINITION_S, 
                 block_consistent_terms) ~ "consistent",
    measure %in% c("iat", "biat", "gnat") & 
      str_detect(BLOCK_PAIRING_DEFINITION_S, 
                 block_inconsistent_terms) ~ "inconsistent",
    measure == "amp" & str_detect(TRIAL_NAME_S, 
                                  trial_consistent_terms) ~ "consistent",
    measure == "amp" & str_detect(TRIAL_NAME_S, 
                                  trial_inconsistent_terms) ~ "inconsistent",
    measure == "siat" & 
      str_detect(BLOCK_PAIRING_DEFINITION_S, 
                 block_consistent_terms) ~ "consistent",
    measure == "siat" & 
      str_detect(BLOCK_PAIRING_DEFINITION_S, 
                 block_inconsistent_terms) ~ "inconsistent",
    measure == "ept" & 
      TRIAL_RESPONSE_S == "Good" & 
      str_detect(TRIAL_NAME_S, 
                 trial_consistent_terms) ~ "consistent",
    measure == "ept" & 
      TRIAL_RESPONSE_S == "Bad" & 
      str_detect(TRIAL_NAME_S,
                 trial_inconsistent_terms) ~ "consistent",
    measure == "ept" & 
      TRIAL_RESPONSE_S == "Good" & 
      str_detect(TRIAL_NAME_S, 
                 trial_inconsistent_terms) ~ "inconsistent",
    measure == "ept" & 
      TRIAL_RESPONSE_S == "Bad" & 
      str_detect(TRIAL_NAME_S, 
                 trial_consistent_terms) ~ "inconsistent"),
    TRIAL_ERROR = as.numeric(TRIAL_ERROR),
    TRIAL_LATENCY = as.numeric(TRIAL_LATENCY),
    score = case_when(measure %in% c("iat", "biat", "siat", "gnat", "ept") ~ TRIAL_LATENCY,
                      measure %in% c("amp") ~ TRIAL_ERROR))

```

# retain only session_ids with the correct number of trials 

```{r}

session_with_complete_n_trials <- critical_trials_df |>
  count(SESSION_ID, domain, measure) |>
  filter((measure == "amp" & n == 48) |
           (measure == "iat" & n == 120) |
           (measure == "biat" & n == 128) |
           (measure == "siat" & n == 192) |
           (measure == "gnat" & n == 160) |
           (measure == "ept" & n == 180))

critical_trials_complete_tasks <- critical_trials_df |>
  semi_join(session_with_complete_n_trials, by = "SESSION_ID")

```

# apply exclusions

## at session level

Exclusions applied same as those from Bar-Anan & Nosek, 2014

```{r}

participants_after_session_level_exclusions <- critical_trials_complete_tasks |>
  mutate(rt_under_300 = case_when(TRIAL_LATENCY < 300 ~ 1,
                                   TRUE ~ 0)) |>
  group_by(SESSION_ID, measure, domain) |>
  summarise(mean_rts_under_300 = mean(rt_under_300),
            mean_errors = mean(TRIAL_ERROR)) |>
  ungroup() |>
  filter(
    (measure %in% c("iat", "biat", "siat", "gnat") & mean_rts_under_300 < .1) 
    |
    (measure %in% c("ept") & mean_errors < .4) # errors are coded as 1
    | 
    (measure %in% c("amp") & (mean_errors < .95 & mean_errors > .05))
  ) |>
  select(SESSION_ID, measure, domain)
  
participants_after_session_level_exclusions |>
  count(measure, domain)

```

## at trial level

Exclusions applied same as those from Bar-Anan & Nosek, 2014

```{r}

all_exclusions_applied_df <- critical_trials_complete_tasks |>
  semi_join(participants_after_session_level_exclusions) |>
  filter(
    (measure %in% c("iat", "biat", "siat") & (TRIAL_LATENCY > 400 & TRIAL_LATENCY < 10000)) 
    |
    (measure %in% c("gnat") & (TRIAL_LATENCY > 400 & TRIAL_LATENCY < 1200) & (TRIAL_ERROR %in% c(0, 3)))
    |
    (measure %in% c("ept") & (1500 >= TRIAL_LATENCY))
    |
    (measure %in% c("amp"))
  )

write_rds(all_exclusions_applied_df, "../../data/processed/data_trials_for_bootstrapping.rds", compress = "gz")
# all_exclusions_applied_df <- read_rds("../../data/processed/data_trials_for_bootstrapping.rds")

```

# bootstrap 95% CIs and compare against neutral point 

```{r}

n_boots = 2000
subset_sample = FALSE # to reduce processing time for testing

if(TRUE){
  
  # Fast calculation of the A statistic - code from Ruscio (2008) supplementary materials
  A_score <- function(data, i) {
    data_with_indexes <- data[i,] # boot function requires data and index
    x  <- na.omit(data_with_indexes$score[data_with_indexes$trial_consistency == "inconsistent"])
    y  <- na.omit(data_with_indexes$score[data_with_indexes$trial_consistency == "consistent"])
    nx <- length(x)
    ny <- length(y)
    rx <- sum(rank(c(x, y))[1:nx])
    A <- (rx / nx - (nx + 1) / 2) / ny
    return(A)
  }
  
  bootstrap_A_score <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = A_score, 
                 R         = n_boots, 
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores()-1)
    
    # results <- boot::boot.ci(fit, conf = 0.95, type = c("bca"))
    # 
    # output <- 
    #   tibble(method   = "bca",
    #          estimate = fit$t0,
    #          ci_lower = results$bca[4],
    #          ci_upper = results$bca[5])
    # returns error: estimated adjustment 'w' is infinite
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("basic"))
    
    output <- 
      tibble(method   = "basic",
             estimate = fit$t0,
             ci_lower = results$basic[4],
             ci_upper = results$basic[5])
    
    return(output)
  }
  
  
  if(subset_sample == TRUE) {
    trials_to_process <- all_exclusions_applied_df |>
      slice_head(n = 500000)
    } else {
    trials_to_process <- all_exclusions_applied_df
  }
  
  # bootstrap A scores 
  A_scores <- trials_to_process |>
    mutate(session_id = as.factor(SESSION_ID),
           trial_consistency = as.character(trial_consistency)) |>
    
    # ensure a sufficient number of observations per person per measure per trial type
    group_by(session_id, measure, domain, trial_consistency) |>
    filter(n() >= 10) |>
    
    # remove those who do not have sufficient observations for both trials per measure
    group_by(session_id, domain, measure) |>
    filter(n_distinct(trial_consistency) == 2) |>
    
    # do bootstrapping scores
    group_by(session_id, measure, domain) |>
    do(bootstrap_A_score(data = .)) |>
    ungroup() |>
    mutate(sig = ifelse((ci_lower < 0.50 & ci_upper < 0.50) | (ci_lower > 0.50 & ci_upper > 0.50), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) 
  
}

```

# split half

```{r}

A_score <- function(data) {
  x  <- na.omit(data$score[data$trial_consistency == "inconsistent"])
  y  <- na.omit(data$score[data$trial_consistency == "consistent"])
  nx <- length(x)
  ny <- length(y)
  rx <- sum(rank(c(x, y))[1:nx])
  A  <- (rx / nx - (nx + 1) / 2) / ny
  return(A)
}

# subset <- all_exclusions_applied_df |>
#   distinct(SESSION_ID) |>
#   slice(1:1000) |>
#   pull(SESSION_ID)

split_half_data <- all_exclusions_applied_df |>
  #filter(SESSION_ID %in% subset) |>
  group_by(SESSION_ID, domain, measure) |>
  mutate(trial_n = row_number()) |>
  ungroup() |>
  mutate(half = case_when(measure == "amp"  & trial_n <= 24 ~ "estimate_first_half",
                          measure == "iat"  & trial_n <= 30 ~ "estimate_first_half",
                          measure == "iat"  & trial_n  > 60 & trial_n <= 90 ~ "estimate_first_half",
                          measure == "biat" & trial_n <= 64 ~ "estimate_first_half",
                          measure == "siat" & trial_n <= 96 ~ "estimate_first_half",
                          measure == "gnat" & trial_n <= 80 ~ "estimate_first_half",
                          measure == "ept"  & trial_n <= 90 ~ "estimate_first_half",
                          TRUE ~ "estimate_second_half")) |>
  mutate(session_id = as.factor(SESSION_ID),
         trial_consistency = as.character(trial_consistency)) |>
  
  # ensure a sufficient number of observations per person per measure per trial type
  group_by(session_id, measure, domain, trial_consistency, half) |>
  filter(n() >= 5) |>

  # remove those who do not have sufficient observations for both trials per measure
  group_by(session_id, domain, measure) |>
  filter(n_distinct(trial_consistency) == 2) |>
  ungroup()

split_half_scores <- split_half_data |>
  # calculate scores
  group_by(session_id, measure, domain, half) %>%
  do(score = A_score(.)) |>
  ungroup() |>
  mutate(score = as.numeric(score)) |>
  mutate(score = ifelse(is.nan(score), NA, score),
         score = ifelse(is.infinite(score), NA, score)) |>
  pivot_wider(names_from = half,
              values_from = score)

```

# write to disk

```{r}

data_processed <- 
  full_join(A_scores, split_half_scores, by = c("session_id", "measure", "domain")) |>
  rename(estimate_first_half = score_first_half,
         estimate_second_half = score_second_half) |>
  drop_na()

write_rds(data_processed, "../../data/processed/data_processed.rds")

```



